# 第四章 机器学习基础
> 除分类和回归之外的机器学习形式有什么？
怎么评估机器学习模型？
数据的准备
特征工程
过拟合怎么解决？
机器学习的通用工作流程？

### 模型评估、数据预处理、特征工程、解决过拟合====> 七步走~

## 一、ML的四个分支
>1. 监督学习：
>>分类/回归/序列生成、语法树预测、目标检测、图像分割

>2. 无监督学习
>>目的在于数据可视化和数据压缩去噪。可以在监督学习之前使用无监督，更好的理解数据。
**降维和聚类**

>3. 自监督学习
>>++**没有人工标签的监督学习，标签仍然存在，不是人工添加，但是是由输入数据，通过启发式算法生成**++。
包括：自编码器/输入视频的一帧或者单词预测下一个（时序监督学习，用未来的输入数据作为监督）

>4. 强化学习

## 二、评估ML的model
关于测试集训练会导致信息泄露，同样会导致模型的泛化能力不够
>当可用数据很少时，有三种经典的评估方法：
>1. 简单的留出验证
>2. K折验证
>3. 带打乱数据的重复K折验证
### 1. 简单的留出验证
```python
'''
简单留出验证的代码：通常需要打乱顺序
'''
num_validation_samples =  10000
#打乱顺序
np.random.shuffle(data)
validation_data = data[:num_validation_samples]	#定义验证集
data = data[num_validation_samples:]

training_data = data[:]	#定义训练集

#训练集训练，验证集评估
model = get_model()
model.train(training_data)
validation_score = model.evaluate(validation_data)

#调节模型，重新训练、评估，然后再次调节
#调节好超参数之后，要在所有的非测试集上重新训练，得到最终的模型
model = get_model()
model.train(np.concatenate([training_data, validation_data]))
test_score = model.evaluate(test_data)
```
>这个方法的问题是：如果数据很少，验证集和测试集的样本太少，所以不同的随机打乱，最终模型的性能差别就很大
### 2. K折验证
> 在第三章的房价预测已经实现过了，不再重复
### 3. 带打乱数据顺序的重复K折验证
>能够在数据很少时候，得到尽可能准确的模型
方法： 多次使用K折验证，每次将数据划分为K个分区之前都先将数据打乱，最终的分数是每次K折验证分数的平均值
缺点： 一共需要训练和评估 P×K 个模型，计算代价太大
### *注意事项
1. 数据代表性：划分数据之前先应该随机打乱顺序
2. 时间箭头： 有时序的预测，不能打乱顺序
3. 数据冗余： 要确保训练集和验证集之间没有交集

## 三、数据预处理、特征工程、特征学习
### 1. 数据预处理
>向量化、标准化、缺失值处理、特征提取

向量化：
>传入的数据必须是张量，浮点数或者整数

标准化：
>数值归一化，对每个特征进行处理，使均值为0，标准差为1---->减去mean，除以标准差
```python
x -= x.mean(axis=0)
x /= x.std(axis=0)
```
缺失值处理：
>当训练数据没有缺失值，测试数据有，可以试着人为生成一些缺失值

### 2. 特征工程
>数据输入之前，利用先验知识，对数据进行硬编码，以改善模型效果
良好的特征可以使用更少的数据，更快的收敛

## 四、过拟合和欠拟合
当不能获得更多的数据时，怎样提高模型的泛化能力？

-----
抑制过拟合：
1. 减小网络大小
2. 添加权重正则化
3. Dropout
------

> 加正则化，来限制模型的存储的信息，以减少模型的过拟合。
### 1. 权重正则化
- 奥卡姆剃刀原理：如果一件事情有两种解释，最可能正确的是更简单假设更少的那一个--->NN:简单模型比复杂模型更不容易过拟合
- 简单模型：**++参数值的分布的熵更小的模型，或者参数更少的模型++**--->可以强制模型权重取较小的值，限制模型的复杂度===>“权重正则化”===>方法：向loss function中添加与较大权重值相关的cost，两种形式L1和L2
- L1正则化：添加的cost与weight的绝对值成正比，weight的L1范数
- L2正则化：添加的cost与weight的平方成正比，L2范数
```python
#keras中，向层传递权重正则化项的实例

#例子：L2正则化
from keras import regularizers

model = model.Sequential()
model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),
			activation='relu', input_shape=(10000,)))
'''
l2(0.001)的含义是：该层权重矩阵的每个系数，都会使网络的loss增加0.001*weight_coefficient_value
'''
model.add(layers.Dense(1, activation='sigmoid'))

#其他的正则化方法
regularizers.l1(0.001)
regularizers.l1_l2(l1=0.001, l2=0.002) #同时做l1和l2正则化
```
### 2. Dropout正则化
>对某一层使用Dropout就是在训练时，随机将这一层的输出舍弃（权重设为0）；
Dropout比率是被设为0的特征所占的比例(**++一般取0.2~0.5++**)；
**++测试时，该层的输出值按照Dropout比例缩小，因为这时候有了更多的神经元被激活，需要加以平衡++**（可以改为在训练时×2，就不用在测试时候÷2了）
- Dropout实际上是在层间引入噪声，打破了不显著的偶然模式，防止模型记住这些偶发模式

### *总结：
防止过拟合的方法：
1. 获得更多数据
2. 减小网络容量
3. 添加权重正则化
4. 添加Dropout
5. BN
6. 还有啥下采样啥的？？？
## 五、ML的通用工作流程
1. 定义问题，收集数据
2. 选择衡量指标
	1. 对于平衡分类，ROC、AUC是常用指标
	2. 类别不平衡，可以采用准确率/召回率
	3. 排序或者多标签，可以采用评价准确率均值（mean average precision）
3. 确定评估方法
	1. 留出验证集
	2. K折交叉验证
	3. 重复的K折验证
4. 准备数据
	1. 向量化、归一化、标准化
	2. 特征工程(尤其是小数据问题)
5. 做个baseline
	1. 三个关键参数：最后一层的激活(限制网络输出，回归的最后一层不用激活)；损失函数(匹配解决问题的类型，回归是mse)；优化器的配置(优化器/学习率，rmsprop挺好的~)
	2. 直接优化衡量的指标可能不能实现(loss function 必须可微，所有ROC、AUC就转化成了替代指标:交叉熵)

![捕获.PNG](https://i.loli.net/2019/05/04/5ccdb0c410108.png)
6. 扩大模型规模：开发过拟合的模型
	1. 层数增多
	2. 每层参数增多
	3. epochs增多
7. 模型正则化和调节超参数
	1. Dropout
	2. 层数变化
	3. L1/L2正则化
	4. 每层单元个数或者学习率等超参数
	5. 特征工程：增删特征











