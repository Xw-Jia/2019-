# 03 最大似然、最大后验、贝叶斯
## 1 贝叶斯公式
![title](https://i.loli.net/2019/03/28/5c9c764579ce1.png)

公式每一项的含义：
![title](https://i.loli.net/2019/03/28/5c9c769658e39.png)

+ posterior：通过样本X得到参数的概率，也就是后验概率。
+ likehood：通过参数得到样本X的概率，似然函数，通常就是我们的数据集的表现。
+ prior：参数的先验概率，一般是根据人的先验知识来得出的。比如人们倾向于认为抛硬币实验会符合先验分布：beta分布。当我们选择beta分布的参数$\alpha=\beta=0.5$时，代表人们认为抛硬币得到正反面的概率都是0.5。
+ evidence：![title](https://i.loli.net/2019/03/28/5c9c77ca7c29e.png)，样本X发生的概率，是各种条件下发生的概率的积分。
**简单来说，求x下$\theta$的概率，这是后验概率，需要用似然函数（参数$\theta$下的x的概率），乘先验概率，再除X发生的总概率。**

## 2 极大似然估计
认为当前发生的事情就是概率最大的事情，所以用给定的数据集，使该数据集发生的概率最大，求出模型中的参数。
::: hljs-center

![title](https://i.loli.net/2019/03/28/5c9c9dfdd0b21.png)

:::
对似然函数两边去对数，生成对数似然，转化成求对数似然函数的最大化的问题：
::: hljs-center

![title](https://i.loli.net/2019/03/28/5c9c9e89dde99.png)

:::
求对数似然函数最大化，可以通过导数为0来求解。
极大似然估计只关注当前的样本，也就是**只关注当前发生的事情，不考虑事情的先验情况**。由于计算简单，而且不需要关注先验知识，因此在机器学习中的应用非常广，最常见的就是逻辑回归。

## 3 最大后验估计
和最大似然估计不同的是，**最大后验估计中引入了先验概率**（先验分布属于贝叶斯学派引入的，像**L1，L2正则化就是对参数引入了拉普拉斯先验分布和高斯先验分布**），而且最大后验估计要求的是：![title](https://i.loli.net/2019/03/28/5c9c9f698add7.png)
![title](https://i.loli.net/2019/03/28/5c9c9f9289204.png)
取对数，得到：
::: hljs-center

![title](https://i.loli.net/2019/03/28/5c9c9fab72b2e.png)

:::
最大后验估计不只是关注当前的样本的情况，还关注已经发生过的先验知识。在朴素贝叶斯中会有最大后验概率的应用，但并没有用上最大后验估计来求参数（因为朴素贝叶斯中的θ其实就是分类的类别）。

**最大后验估计和最大似然估计的区别**：最大后验估计允许我们把先验知识加入到估计模型中，这*在样本很少的时候是很有用的*（**因此朴素贝叶斯在较少的样本下就能有很好的表现**），**因为样本很少的时候我们的观测结果很可能出现偏差，此时先验知识会把估计的结果“拉”向先验**，实际的预估结果将会在先验结果的两侧形成一个顶峰。通过调节先验分布的参数，比如beta分布的α，β，我们还可以调节把估计的结果“拉”向先验的幅度，α，β越大，这个顶峰越尖锐。这样的参数，我们叫做预估模型的“超参数”。

## 4 贝叶斯估计
贝叶斯估计和极大后验估计有点相似，都是以最大化后验概率为目的。区别在于：
1）极大似然估计和极大后验估计都是只返回了的预估值。
2）极大后验估计在计算后验概率的时候，把分母p(X)给忽略了，在进行贝叶斯估计的时候则不能忽略
3）**贝叶斯估计要计算整个后验概率的概率分布**

对于一个特定的似然函数，如果我们**选定一个先验概率分布，得到的后验概率分布和先验概率分布相同，则似然函数分布和先验概率分布就组成了一对共轭分布**。此时训练出来的是后延概率分布，而不再是单一的值。

　　举几个例子：

likehood为高斯分布，prior为高斯分布，则posterior也为高斯分布。
likehood为伯努利分布（二项式分布），prior为beta分布，则posterior也为beta分布。
likehood为多项式分布，prior为Dirichlet分布（beta分布的一个扩展），则posterior也为Dirichlet（狄利克雷）分布。beta分布可以看作是dirichlet分布的特殊情况。

根据上面的描述，在实践中我们**往往会选择共轭先验来简化**。在把后验概率推导为和先验概率一样的分布形式的时候，分母p(X)其实可以看做一个常数，往往充当了一个normalize，归一化的作用。
**求解的时候，既然我们根据先验分布知道了后验是什么分布，那我们求出后验分布的期望值（知道了分布情况就很容易求得期望值），即是需要估计的参数的值：**
::: hljs-center

![title](https://i.loli.net/2019/03/28/5c9ca8bf7d875.png)

:::
贝叶斯估计相对于最大后验估计的好处还在于，贝叶斯估计计算了整个后验概率的分布，从而也能求出其他一些比如分布的方差之类的值来供参考，比如计算出来方差太大的，我们可以认为分布不够好，从而把这个当做选择超参数的一个考虑因素。实际上，贝叶斯估计会比MAP把估计的结果往先验结果“拉”的程度还提高了一些，从而使估计结果更靠近先验结果。

　　贝叶斯估计的应用有LDA主题模型。LDA主题模型通过共轭分布的特性来求出主题分布和词分布。



