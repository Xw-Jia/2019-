# 01 SVM原理及要点
**参考博客地址[微笑sun](https://www.cnblogs.com/jiangxinyang/p/9217424.html)**
>SVM原来处理二分类问题，经过进化，也可以处理多元线性分类和非线性的问题，同时处理回归问题。在深度学习兴起之前，是最好的分类算法。
**现在，在小样本的问题上，SVM仍然很好用**

## 1 感知机模型
>感知机模型是**二分类的线性分类器**，尝试找到超平面分开数据集，二维空间中，超平面是个直线，三维空间中则是一个平面。

感知机的模型：

$$f(x) = sign(W*x+b)$$

$sign(x)$是指示函数，自变量大于0取1，小于零取-1
![感知机](https://i.loli.net/2019/03/28/5c9c4c841e95f.png)

对于正确分类的点，$y(Wx+b) > 0$,对于错误分类的点，$<0$，所以，采用损失函数，使所有误分类的点到超平面的距离之和最小。

$$-\frac{1}{\begin{Vmatrix}w\end{Vmatrix}}\sum_{x_i\in{M}}y_i(w*x_i+b)$$

其中，M是表示**误分类的样本集合**，所以，最终得到的**感知机的损失函数**是：
$$L(w,b)=-\sum_{x_i\in{M}}y_i(w*x_i+b)$$

## 2 SVM
>感知机中，目标是将训练集分开，**而能够将样本分开的超平面有很多**。SVM本质上类似于感知机，但是要求却更加苛刻。

***远离超平面的点是安全的，容易被误分类的点离超平面很近。SVM的思想是重点关注离超平面很近的点***====>**++在分类正确的同时，让离超平面最近的点到超平面的距离最大++**







